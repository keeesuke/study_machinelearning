{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "caa44bc10a9d34d96916eba5a4f90dba73e84735"
   },
   "source": [
    "Due to leaks found in the past week, I wondered how it would modify the simple XGB scoring method demonstrated in this notebook.\n",
    "\n",
    "For this purpose I use the results found in : https://www.kaggle.com/johnfarrell/breaking-lb-fresh-start-with-lag-selection/output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e9fddf207ae05e8c1d0e76ce43f12df6252acee"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.read_csv('../input/santander-value-prediction-challenge/train.csv')\n",
    "target = np.log1p(data['target'])\n",
    "data.drop(['ID', 'target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "632e6a2563936127c06287cfc3a1cf309385934e"
   },
   "source": [
    "### Add train leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "leak = pd.read_csv('../input/breaking-lb-fresh-start-with-lag-selection/train_leak.csv')\n",
    "data['leak'] = leak['compiled_leak'].values\n",
    "data['log_leak'] = np.log1p(leak['compiled_leak'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c8610c5187001d7ec17a7ffaf203859c6f9aa46"
   },
   "source": [
    "### Feature Scoring using XGBoost with the leak feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68e309e111e4a772a6ec4d8cf00c11e134c23f05",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** .5\n",
    "\n",
    "reg = XGBRegressor(n_estimators=1000)\n",
    "folds = KFold(4, True, 134259)\n",
    "fold_idx = [(trn_, val_) for trn_, val_ in folds.split(data)]\n",
    "scores = []\n",
    "\n",
    "nb_values = data.nunique(dropna=False)\n",
    "nb_zeros = (data == 0).astype(np.uint8).sum(axis=0)\n",
    "\n",
    "features = [f for f in data.columns if f not in ['log_leak', 'leak', 'target', 'ID']]\n",
    "for _f in features:\n",
    "    score = 0\n",
    "    for trn_, val_ in fold_idx:\n",
    "        reg.fit(\n",
    "            data[['log_leak', _f]].iloc[trn_], target.iloc[trn_],\n",
    "            eval_set=[(data[['log_leak', _f]].iloc[val_], target.iloc[val_])],\n",
    "            eval_metric='rmse',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False\n",
    "        )\n",
    "        score += rmse(target.iloc[val_], reg.predict(data[['log_leak', _f]].iloc[val_], ntree_limit=reg.best_ntree_limit)) / folds.n_splits\n",
    "    scores.append((_f, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3694822b9bc81bb6896f417cee646e1990577917"
   },
   "source": [
    "### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7863f32d4b51d6dc957453365d8e79682848f4e4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = pd.DataFrame(scores, columns=['feature', 'rmse']).set_index('feature')\n",
    "report['nb_zeros'] = nb_zeros\n",
    "report['nunique'] = nb_values\n",
    "report.sort_values(by='rmse', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60fdbaefae3d78b8f27cb109d2f5caf38fd9646a"
   },
   "source": [
    "### Plot a few diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "660318ef180911d56dc1fadca3ea196917a92c22",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.xlabel('Number of zeros in the feature', fontsize=14)\n",
    "plt.ylabel('Feature RMSE (on np.log1p)', fontsize=14)\n",
    "plt.title('Feature score vs number of zeros', fontsize=16, fontweight='bold', color='#ae3453')\n",
    "plt.scatter(report['nb_zeros'], report['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "deb4e77513ce86867a6d653e9da6c74e2aed768d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "plt.xlabel('Number of unique values in the feature', fontsize=14)\n",
    "plt.ylabel('Feature RMSE (on np.log1p)', fontsize=14)\n",
    "ax.set_title('Feature score vs number of unique values', fontsize=16, fontweight='bold', color='#ae3453')\n",
    "scatter = ax.scatter(report['nunique'], report['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b8231eee7ab03863592853a2c8aa59e7a39d2e19",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_file, output_notebook, ColumnDataSource\n",
    "\n",
    "report.sort_values('rmse', ascending=False, inplace=True)\n",
    "\n",
    "radii = 1000 * (report['rmse'].max() - report['rmse']).values\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x=report['nunique'].tolist(),\n",
    "    y=report['nb_zeros'].tolist(),\n",
    "    desc=report.index.tolist(),\n",
    "    radius=radii,\n",
    "    fill_color=[\n",
    "       \"#%02x%02x%02x\" % (int(r), 100, 150) for r in 255 * ((report['rmse'].max() - report['rmse']) / (report['rmse'].max() - report['rmse'].min())).values\n",
    "    ],\n",
    "    rmse=report['rmse'].tolist()\n",
    "))\n",
    "\n",
    "TOOLTIPS = [\n",
    "    (\"rmse\", \"@rmse\"),\n",
    "    (\"(nunique, nb_zeros)\", \"(@x, @y)\"),\n",
    "    (\"feature\", \"@desc\"),\n",
    "]\n",
    "TOOLS = \"hover, crosshair, pan, wheel_zoom, zoom_in, zoom_out, box_zoom, undo, redo, reset, tap, save, box_select, poly_select, lasso_select\"\n",
    "\n",
    "p = figure(plot_width=600, plot_height=600, tooltips=TOOLTIPS, tools=TOOLS,\n",
    "           title=\"Number of unique values vs Number of zeros\")\n",
    "p.xaxis.axis_label = 'Number of unique values in feature'\n",
    "p.yaxis.axis_label = 'Number of zeros in feature'\n",
    "p.xaxis.axis_label_text_font_style ='bold'\n",
    "p.yaxis.axis_label_text_font_style ='bold'\n",
    "p.title.text_color = '#ae3453'\n",
    "p.title.text_font_size = '16pt'\n",
    "p.scatter(\n",
    "    'x', 'y', source=source,\n",
    "    radius='radius',\n",
    "    fill_color='fill_color',\n",
    "    line_color=None,\n",
    "    fill_alpha=0.8\n",
    ")\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "show(p)  # open a browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4db7b58fc5b7dc4acb58b0b23a3e05f46dc612e2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report.to_csv('feature_report.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0036802c721bc8082d74e17fd9454aed9939a386"
   },
   "source": [
    "### Select some features (threshold is not optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a8a6ce954124e2a42dddc19c5f55174f86c8984",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_features = report.loc[report['rmse'] <= 0.7925].index\n",
    "rmses = report.loc[report['rmse'] <= 0.7925, 'rmse'].values\n",
    "good_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75dfb7f6467ba6cddc0648d4452fa4968c63c484"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/santander-value-prediction-challenge/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c4a7885aae0243a8e5e97ad7b564f2f0d1804ba"
   },
   "source": [
    "### Display distributions of test and train for selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9172be793b24b90bc0d729ee5c2583cd1c74c60b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, f in enumerate(good_features):\n",
    "    plt.subplots(figsize=(10, 3))\n",
    "    plt.title('Feature %s RMSE %.3f train/test distributions' % (f, rmses[i]), fontsize=16, fontweight='bold', color='#ae3453')\n",
    "    hists = plt.hist(np.log1p(data[f].replace(0, np.nan).dropna().values), alpha=.7, label='train', \n",
    "             bins=50, density=True,  histtype='bar')\n",
    "    plt.hist(np.log1p(test[f].replace(0, np.nan).dropna().values), alpha=.5, label='test', \n",
    "             bins=hists[1], density=True, histtype='bar')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9144fdbff21261ea77f7a900f15ef079474f4b16",
    "collapsed": true
   },
   "source": [
    "### Add leak to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ed1665c3928cd9063296de5791a7f9b869a7619"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tst_leak = pd.read_csv('../input/breaking-lb-fresh-start-with-lag-selection/test_leak.csv')\n",
    "test['leak'] = tst_leak['compiled_leak']\n",
    "test['log_leak'] = np.log1p(tst_leak['compiled_leak'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d681176d6c0dd3b5fdcdd6ea610fd229368ea57f"
   },
   "source": [
    "### Train lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8d31ec188185853b05a562a97ffa6982b52e1ce"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Use all features for stats\n",
    "features = [f for f in data if f not in ['ID', 'leak', 'log_leak', 'target']]\n",
    "data.replace(0, np.nan, inplace=True)\n",
    "data['log_of_mean'] = np.log1p(data[features].replace(0, np.nan).mean(axis=1))\n",
    "data['mean_of_log'] = np.log1p(data[features]).replace(0, np.nan).mean(axis=1)\n",
    "data['log_of_median'] = np.log1p(data[features].replace(0, np.nan).median(axis=1))\n",
    "data['nb_nans'] = data[features].isnull().sum(axis=1)\n",
    "data['the_sum'] = np.log1p(data[features].sum(axis=1))\n",
    "data['the_std'] = data[features].std(axis=1)\n",
    "data['the_kur'] = data[features].kurtosis(axis=1)\n",
    "\n",
    "test.replace(0, np.nan, inplace=True)\n",
    "test['log_of_mean'] = np.log1p(test[features].replace(0, np.nan).mean(axis=1))\n",
    "test['mean_of_log'] = np.log1p(test[features]).replace(0, np.nan).mean(axis=1)\n",
    "test['log_of_median'] = np.log1p(test[features].replace(0, np.nan).median(axis=1))\n",
    "test['nb_nans'] = test[features].isnull().sum(axis=1)\n",
    "test['the_sum'] = np.log1p(test[features].sum(axis=1))\n",
    "test['the_std'] = test[features].std(axis=1)\n",
    "test['the_kur'] = test[features].kurtosis(axis=1)\n",
    "\n",
    "# Only use good features, log leak and stats for training\n",
    "features = good_features.tolist()\n",
    "features = features + ['log_leak', 'log_of_mean', 'mean_of_log', 'log_of_median', 'nb_nans', 'the_sum', 'the_std', 'the_kur']\n",
    "dtrain = lgb.Dataset(data=data[features], \n",
    "                     label=target, free_raw_data=False)\n",
    "test['target'] = 0\n",
    "\n",
    "dtrain.construct()\n",
    "oof_preds = np.zeros(data.shape[0])\n",
    "\n",
    "for trn_idx, val_idx in folds.split(data):\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 58,\n",
    "        'subsample': 0.6143,\n",
    "        'colsample_bytree': 0.6453,\n",
    "        'min_split_gain': np.power(10, -2.5988),\n",
    "        'reg_alpha': np.power(10, -2.2887),\n",
    "        'reg_lambda': np.power(10, 1.7570),\n",
    "        'min_child_weight': np.power(10, -0.1477),\n",
    "        'verbose': -1,\n",
    "        'seed': 3,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'metric': 'l2',\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(\n",
    "        params=lgb_params,\n",
    "        train_set=dtrain.subset(trn_idx),\n",
    "        valid_sets=dtrain.subset(val_idx),\n",
    "        num_boost_round=10000, \n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=0\n",
    "    )\n",
    "\n",
    "    oof_preds[val_idx] = clf.predict(dtrain.data.iloc[val_idx])\n",
    "    test['target'] += clf.predict(test[features]) / folds.n_splits\n",
    "    print(mean_squared_error(target.iloc[val_idx], \n",
    "                             oof_preds[val_idx]) ** .5)\n",
    "\n",
    "data['predictions'] = oof_preds\n",
    "data.loc[data['leak'].notnull(), 'predictions'] = np.log1p(data.loc[data['leak'].notnull(), 'leak'])\n",
    "print('OOF SCORE : %9.6f' \n",
    "      % (mean_squared_error(target, oof_preds) ** .5))\n",
    "print('OOF SCORE with LEAK : %9.6f' \n",
    "      % (mean_squared_error(target, data['predictions']) ** .5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "949a9ce471a9041d842f94a3a2ad139587b5edd1"
   },
   "source": [
    "### Save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "513e25d309100480da7dcacf2049598b69d7fbe6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['target'] = np.expm1(test['target'])\n",
    "test.loc[test['leak'].notnull(), 'target'] = test.loc[test['leak'].notnull(), 'leak']\n",
    "test[['ID', 'target']].to_csv('leaky_submission.csv', index=False, float_format='%.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
