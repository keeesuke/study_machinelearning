{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keisuke/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/keisuke/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/keisuke/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "col = [c for c in train.columns if c not in ['id','target']]\n",
    "print(len(col))\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "print(len(col))\n",
    "\n",
    "train = train.replace(-1, np.NaN)\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "train = train.fillna(-1)\n",
    "one_hot = {c: list(train[c].unique()) for c in train.columns if c not in ['id','target']}\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c:\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "    for c in one_hot:\n",
    "        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n",
    "            for val in one_hot[c]:\n",
    "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "def gini(y, pred):\n",
    "    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    g = 2 * metrics.auc(fpr, tpr) -1\n",
    "    return g\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred)\n",
    "\n",
    "params = {'eta': 0.08, 'max_depth': 4, 'objective': 'binary:logistic', 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 0.77, 'scale_pos_weight': 1.6, 'gamma': 10, 'reg_alpha': 8, 'reg_lambda': 1.3, 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train, train['target'], test_size=0.25, random_state=99)\n",
    "\n",
    "x1 = multi_transform(x1)\n",
    "x2 = multi_transform(x2)\n",
    "test = multi_transform(test)\n",
    "\n",
    "col = [c for c in x1.columns if c not in ['id','target']]\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "print(x1.values.shape, x2.values.shape)\n",
    "\n",
    "#remove duplicates\n",
    "tdups = multi_transform(train)\n",
    "dups = tdups[tdups.duplicated(subset=col, keep=False)]\n",
    "\n",
    "x1 = x1[~(x1['id'].isin(dups['id'].values))]\n",
    "x2 = x2[~(x2['id'].isin(dups['id'].values))]\n",
    "print(x1.values.shape, x2.values.shape)\n",
    "\n",
    "y1 = x1['target']\n",
    "y2 = x2['target']\n",
    "x1 = x1[col]\n",
    "x2 = x2[col]\n",
    "\n",
    "#XGBoost\n",
    "watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "model = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, feval=gini_xgb, maximize=True, verbose_eval=20, early_stopping_rounds=20)\n",
    "test['target'] = model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit+10)\n",
    "test['target'] = (np.exp(test['target'].values) - 1.0).clip(0,1)\n",
    "test[['id','target']].to_csv('xgb_submission.csv', index=False, float_format='%.5f')\n",
    "\n",
    "#LightGBM\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True\n",
    "\n",
    "params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'max_bin': 10, 'subsample': 0.8, 'subsample_freq': 10, 'colsample_bytree': 0.8, 'min_child_samples': 500, 'metric': 'auc', 'is_training_metric': False, 'seed': 99}\n",
    "model2 = lgb.train(params, lgb.Dataset(x1, label=y1), 1000, lgb.Dataset(x2, label=y2), verbose_eval=50, feval=gini_lgb, early_stopping_rounds=200)\n",
    "test['target'] = model2.predict(test[col], num_iteration=model2.best_iteration)\n",
    "test['target'] = (np.exp(test['target'].values) - 1.0).clip(0,1)\n",
    "test[['id','target']].to_csv('lgb_submission.csv', index=False, float_format='%.5f')\n",
    "\n",
    "df1 = pd.read_csv('xgb_submission.csv')\n",
    "df2 = pd.read_csv('lgb_submission.csv')\n",
    "df2.columns = [x+'_' if x not in ['id'] else x for x in df2.columns]\n",
    "blend = pd.merge(df1, df2, how='left', on='id')\n",
    "for c in df1.columns:\n",
    "    if c != 'id':\n",
    "        blend[c] = (blend[c] * 0.4)  + (blend[c+'_'] * 0.6)\n",
    "blend = blend[df1.columns]\n",
    "blend['target'] = (np.exp(blend['target'].values) - 1.0).clip(0,1)\n",
    "blend.to_csv('blend1.csv', index=False, float_format='%.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
